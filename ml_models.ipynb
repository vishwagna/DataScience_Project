{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf16e38-9e99-4c81-8857-49c4192821f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32becc57-c829-4acd-a18a-5b290afacb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a84d84e8-d3a9-4b07-8cff-d9944d6392bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('reduced_data.csv')\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['NAME OF STUDENT', 'ROLL NO','DEPARTMENT','GAME','WINNERS OF 2023','GENDER'])\n",
    "y = df['WINNERS OF 2023']  # We use winner_2023 as a proxy to train the model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee6666e-6b38-4ecf-b0b6-741df47f5f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression(random_state=42)\n",
      "Accuracy: 0.9439\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC-AUC Score: 0.6108\n",
      "--------------------------\n",
      "Model: RandomForestClassifier(random_state=42)\n",
      "Accuracy: 0.9346\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC-AUC Score: 0.8531\n",
      "--------------------------\n",
      "Model: SVC(probability=True, random_state=42)\n",
      "Accuracy: 0.9439\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC-AUC Score: 0.4453\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GradientBoostingClassifier(random_state=42)\n",
      "Accuracy: 0.9439\n",
      "Precision: 0.5000\n",
      "Recall: 0.0833\n",
      "F1 Score: 0.1429\n",
      "ROC-AUC Score: 0.8298\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Support Vector Machine': SVC(random_state=42, probability=True),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "   # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    print('Model:',model)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'ROC-AUC Score: {roc_auc:.4f}')\n",
    "    print('--------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4cb4a5-8d13-4061-a08e-368e85e0fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set with Gradient Boosting: 94.39%\n",
      "Mean Absolute Error (MAE): 0.056074766355140186\n",
      "Mean Squared Error (MSE): 0.056074766355140186\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create and train a Gradient Boosting classifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on the test set with Gradient Boosting: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "\n",
    "\n",
    "actual_values = y_test  # Replace 'Actual_Target_Column' with the actual column name\n",
    "predicted_values = y_pred  # Replace 'Predicted_Target_Column' with the predicted column name\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(actual_values, predicted_values)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(actual_values, predicted_values)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b6e733f-e1e1-4a85-9ae8-87efd28a9989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted  Probability\n",
      "708       0          0     0.012504\n",
      "215       0          0     0.103912\n",
      "882       0          0     0.011316\n",
      "88        0          1     0.758707\n",
      "842       0          0     0.160470\n",
      "..      ...        ...          ...\n",
      "451       0          0     0.002838\n",
      "602       1          0     0.010384\n",
      "650       0          0     0.030763\n",
      "582       0          0     0.003219\n",
      "277       1          0     0.246025\n",
      "\n",
      "[214 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'Probability': y_prob\n",
    "})\n",
    "\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec0d88-5365-4b35-a05d-eec4e0a38814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef460d62-0f70-44ec-af1a-ad10dda41116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95f80a38-5fe2-47e3-beb9-a9b7fdd50227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6818181818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.33      0.40         3\n",
      "         1.0       0.60      0.75      0.67         8\n",
      "         2.0       0.80      0.73      0.76        11\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.63      0.60      0.61        22\n",
      "weighted avg       0.69      0.68      0.68        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['GAME'] = label_encoder.fit_transform(df['GAME'])\n",
    "df['DEPARTMENT'] = label_encoder.fit_transform(df['DEPARTMENT'])\n",
    "df['GENDER'] = label_encoder.fit_transform(df['GENDER'])\n",
    "df['PART OF NSO OR NOT'] = df['PART OF NSO OR NOT'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Aggregating the Data: Find the department with the most winners per game\n",
    "df_winners = df[df['WINNERS OF 2023'] == 1]  # Only consider students who won\n",
    "df_dept_winners = df_winners.groupby(['GAME', 'DEPARTMENT']).size().reset_index(name='WIN_COUNT')\n",
    "\n",
    "# Find the department with max wins per game\n",
    "df_dept_winners = df_dept_winners.loc[df_dept_winners.groupby('GAME')['WIN_COUNT'].idxmax()]\n",
    "\n",
    "# Rename for clarity\n",
    "df_dept_winners.rename(columns={'DEPARTMENT': 'WINNING_DEPARTMENT_2023'}, inplace=True)\n",
    "\n",
    "# Merge with main dataset\n",
    "df = df.merge(df_dept_winners[['GAME', 'WINNING_DEPARTMENT_2023']], on='GAME', how='left')\n",
    "\n",
    "# Shift department winners to create a prediction target\n",
    "df['WINNING_DEPARTMENT_2024'] = df['WINNING_DEPARTMENT_2023'].shift(-1)  # Move winners forward\n",
    "\n",
    "# Drop NaN rows after shifting\n",
    "df = df.dropna(subset=['WINNING_DEPARTMENT_2024'])\n",
    "\n",
    "# Define features and target\n",
    "features = ['GAME', 'GENDER', 'PARTICIPATION IN 2022', 'PARTICIPATION IN 2023', 'PART OF NSO OR NOT', 'BATCH']\n",
    "target = 'WINNING_DEPARTMENT_2024'  # Now predicting 2024\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Predict department winners for 2024 per sport\n",
    "future_participants = df[features]  # Using 2023 data to predict 2024 winners\n",
    "df['PREDICTED_WINNING_DEPARTMENT_2024'] = model.predict(future_participants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "368364ad-0b00-481e-9404-494450147688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GAME'] = game_encoder.fit_transform(df['GAME'])\n",
    "df['WINNING_DEPARTMENT_2023'] = dept_encoder.fit_transform(df['WINNING_DEPARTMENT_2023'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "393f33e0-c129-4e0c-9775-ed9155fa9a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_dict={}\n",
    "game_dict[0]='Badminton'\n",
    "game_dict[1]='Basketball'\n",
    "game_dict[2]='Football'\n",
    "game_dict[3]='Cricket'\n",
    "game_dict[4]='Volleyball'\n",
    "game_dict[5]='Table Tennis'\n",
    "game_dict[6]='Tennis'\n",
    "game_dict[7]='Carroms'\n",
    "game_dict[8]='Kabaddi'\n",
    "game_dict[9]='Chess'\n",
    "\n",
    "dept_dict={}\n",
    "dept_dict[0]='CSE'\n",
    "dept_dict[1]='ECE'\n",
    "dept_dict[2]='MECH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d71f1b3a-da3f-4d62-b3ce-94e8fa9b2fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Predicted Winning Departments for 2024 üèÜ\n",
      "\n",
      "üéØ Game: Badminton ‚Üí üèÖ Winning Department: ECE\n",
      "üéØ Game: Basketball ‚Üí üèÖ Winning Department: ECE\n",
      "üéØ Game: Volleyball ‚Üí üèÖ Winning Department: MECH\n",
      "üéØ Game: Table Tennis ‚Üí üèÖ Winning Department: MECH\n",
      "üéØ Game: Tennis ‚Üí üèÖ Winning Department: CSE\n",
      "üéØ Game: Carroms ‚Üí üèÖ Winning Department: CSE\n",
      "üéØ Game: Kabaddi ‚Üí üèÖ Winning Department: ECE\n",
      "üéØ Game: Chess ‚Üí üèÖ Winning Department: CSE\n"
     ]
    }
   ],
   "source": [
    "df['PREDICTED_WINNING_DEPARTMENT_2024'] = df['PREDICTED_WINNING_DEPARTMENT_2024'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Select only unique game-wise predictions for display\n",
    "predictions = df.groupby('GAME')['PREDICTED_WINNING_DEPARTMENT_2024'].agg(lambda x: x.mode()[0]).reset_index()\n",
    "\n",
    "# Print predictions in a readable format\n",
    "print(\"\\nüèÜ Predicted Winning Departments for 2024 üèÜ\\n\")\n",
    "for index, row in predictions.iterrows():\n",
    "    print(f\"üéØ Game: {game_dict[row['GAME']]} ‚Üí üèÖ Winning Department: {dept_dict[row['PREDICTED_WINNING_DEPARTMENT_2024']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ededf6-026b-4272-96be-f43bd04b8af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
